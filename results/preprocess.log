2022-10-11 08:56:45,292 processing notes file
2022-10-11 08:57:54,419 Total number of rows: 2769
2022-10-11 08:57:54,419 Total number of unique HADM_ID (disch_full): 2630
2022-10-11 08:57:54,875 Started Preprocessing raw MIMIC-III data
2022-10-11 08:57:56,541 Total unique HADM_ID (original): 58976
2022-10-11 08:57:56,577 Total unique HADM_ID (ALL_CODES_filtered): 2630
2022-10-11 08:57:56,580 Total unique ICD9_CODE (ALL_CODES_filtered): 3290
2022-10-11 08:57:56,689 Merging discharge summary and ICD codes
2022-10-11 08:57:57,146 Total number of unique HADM_ID (merged): 2630
2022-10-11 08:57:58,090 Total rows in train_full.csv: 2408
2022-10-11 08:57:58,542 Total rows in dev_full.csv: 80
2022-10-11 08:57:58,586 Total rows in test_full.csv: 142
2022-10-11 08:57:59,030 Total rows in train_50.csv: 1539
2022-10-11 08:57:59,362 Total rows in dev_50.csv: 513
2022-10-11 08:57:59,569 Total rows in test_50.csv: 513
2022-10-11 08:58:09,722 
**********************************************

2022-10-11 08:58:09,722 Training CBOW embedding...
2022-10-11 08:58:09,723 Params: embed_size=128, workers=7, min_count=0, window=5, negative=5
2022-10-11 08:58:09,723 Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=128, alpha=0.025>', 'datetime': '2022-10-11T08:58:09.723709', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}
2022-10-11 08:58:09,724 collecting all words and their counts
2022-10-11 08:58:09,724 PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
2022-10-11 08:58:10,284 PROGRESS: at sentence #10000, processed 2484113 words, keeping 28568 word types
2022-10-11 08:58:10,302 PROGRESS: at sentence #20000, processed 2536825 words, keeping 29530 word types
2022-10-11 08:58:10,316 collected 29679 word types from a corpus of 2557278 raw words and 25036 sentences
2022-10-11 08:58:10,316 Creating a fresh vocabulary
2022-10-11 08:58:10,498 Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 29679 unique words (100.00% of original 29679, drops 0)', 'datetime': '2022-10-11T08:58:10.498232', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}
2022-10-11 08:58:10,498 Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 2557278 word corpus (100.00% of original 2557278, drops 0)', 'datetime': '2022-10-11T08:58:10.498232', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}
2022-10-11 08:58:10,802 deleting the raw counts dictionary of 29679 items
2022-10-11 08:58:10,803 sample=0.001 downsamples 29 most-common words
2022-10-11 08:58:10,803 Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2431823.5803488838 word corpus (95.1%% of prior 2557278)', 'datetime': '2022-10-11T08:58:10.803045', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}
2022-10-11 08:58:11,264 estimated required memory for 29679 words and 128 dimensions: 45230796 bytes
2022-10-11 08:58:11,264 resetting layer weights
2022-10-11 08:58:11,286 Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-10-11T08:58:11.285749', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}
2022-10-11 08:58:11,286 Word2Vec lifecycle event {'msg': 'training model with 7 workers on 29679 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-10-11T08:58:11.286749', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}
2022-10-11 08:58:12,294 EPOCH 0 - PROGRESS: at 6.89% examples, 1233111 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:12,999 EPOCH 0: training on 2557278 raw words (2431588 effective words) took 1.7s, 1422902 effective words/s
2022-10-11 08:58:14,020 EPOCH 1 - PROGRESS: at 4.65% examples, 815584 words/s, in_qsize 14, out_qsize 2
2022-10-11 08:58:15,031 EPOCH 1 - PROGRESS: at 10.52% examples, 1074933 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:15,712 EPOCH 1: training on 2557278 raw words (2432076 effective words) took 2.7s, 897602 effective words/s
2022-10-11 08:58:16,719 EPOCH 2 - PROGRESS: at 6.77% examples, 1206012 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:17,678 EPOCH 2: training on 2557278 raw words (2431791 effective words) took 2.0s, 1238662 effective words/s
2022-10-11 08:58:18,682 EPOCH 3 - PROGRESS: at 8.98% examples, 1768593 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:19,047 EPOCH 3: training on 2557278 raw words (2431928 effective words) took 1.4s, 1779099 effective words/s
2022-10-11 08:58:20,058 EPOCH 4 - PROGRESS: at 9.69% examples, 1943554 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:20,333 EPOCH 4: training on 2557278 raw words (2432119 effective words) took 1.3s, 1895936 effective words/s
2022-10-11 08:58:21,338 EPOCH 5 - PROGRESS: at 9.07% examples, 1794290 words/s, in_qsize 12, out_qsize 1
2022-10-11 08:58:21,686 EPOCH 5: training on 2557278 raw words (2431861 effective words) took 1.4s, 1800966 effective words/s
2022-10-11 08:58:22,691 EPOCH 6 - PROGRESS: at 9.46% examples, 1890911 words/s, in_qsize 12, out_qsize 1
2022-10-11 08:58:22,975 EPOCH 6: training on 2557278 raw words (2431183 effective words) took 1.3s, 1890433 effective words/s
2022-10-11 08:58:23,981 EPOCH 7 - PROGRESS: at 9.81% examples, 1987094 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:24,226 EPOCH 7: training on 2557278 raw words (2431594 effective words) took 1.2s, 1948672 effective words/s
2022-10-11 08:58:25,232 EPOCH 8 - PROGRESS: at 8.94% examples, 1755217 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:25,623 EPOCH 8: training on 2557278 raw words (2431740 effective words) took 1.4s, 1743185 effective words/s
2022-10-11 08:58:26,632 EPOCH 9 - PROGRESS: at 7.99% examples, 1498060 words/s, in_qsize 14, out_qsize 1
2022-10-11 08:58:27,248 EPOCH 9: training on 2557278 raw words (2431290 effective words) took 1.6s, 1499526 effective words/s
2022-10-11 08:58:28,264 EPOCH 10 - PROGRESS: at 8.15% examples, 1529228 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:28,764 EPOCH 10: training on 2557278 raw words (2431917 effective words) took 1.5s, 1607114 effective words/s
2022-10-11 08:58:29,767 EPOCH 11 - PROGRESS: at 9.26% examples, 1841794 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:30,095 EPOCH 11: training on 2557278 raw words (2431597 effective words) took 1.3s, 1831811 effective words/s
2022-10-11 08:58:31,098 EPOCH 12 - PROGRESS: at 8.80% examples, 1717155 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:31,499 EPOCH 12: training on 2557278 raw words (2431982 effective words) took 1.4s, 1734941 effective words/s
2022-10-11 08:58:32,504 EPOCH 13 - PROGRESS: at 8.47% examples, 1624670 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:32,999 EPOCH 13: training on 2557278 raw words (2431565 effective words) took 1.5s, 1624083 effective words/s
2022-10-11 08:58:34,008 EPOCH 14 - PROGRESS: at 8.40% examples, 1601367 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:34,461 EPOCH 14: training on 2557278 raw words (2432172 effective words) took 1.5s, 1667937 effective words/s
2022-10-11 08:58:35,469 EPOCH 15 - PROGRESS: at 8.89% examples, 1734267 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:35,860 EPOCH 15: training on 2557278 raw words (2432054 effective words) took 1.4s, 1742525 effective words/s
2022-10-11 08:58:36,864 EPOCH 16 - PROGRESS: at 8.98% examples, 1768585 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:37,249 EPOCH 16: training on 2557278 raw words (2431566 effective words) took 1.4s, 1752892 effective words/s
2022-10-11 08:58:38,255 EPOCH 17 - PROGRESS: at 8.59% examples, 1659191 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:38,744 EPOCH 17: training on 2557278 raw words (2431348 effective words) took 1.5s, 1629789 effective words/s
2022-10-11 08:58:39,754 EPOCH 18 - PROGRESS: at 8.54% examples, 1635291 words/s, in_qsize 12, out_qsize 1
2022-10-11 08:58:40,212 EPOCH 18: training on 2557278 raw words (2431526 effective words) took 1.5s, 1659309 effective words/s
2022-10-11 08:58:41,224 EPOCH 19 - PROGRESS: at 8.80% examples, 1703478 words/s, in_qsize 11, out_qsize 2
2022-10-11 08:58:41,631 EPOCH 19: training on 2557278 raw words (2431573 effective words) took 1.4s, 1717864 effective words/s
2022-10-11 08:58:42,643 EPOCH 20 - PROGRESS: at 8.32% examples, 1577623 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:43,231 EPOCH 20: training on 2557278 raw words (2431602 effective words) took 1.6s, 1523002 effective words/s
2022-10-11 08:58:44,237 EPOCH 21 - PROGRESS: at 7.60% examples, 1403213 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:45,014 EPOCH 21: training on 2557278 raw words (2432156 effective words) took 1.8s, 1366277 effective words/s
2022-10-11 08:58:46,022 EPOCH 22 - PROGRESS: at 7.99% examples, 1498537 words/s, in_qsize 11, out_qsize 2
2022-10-11 08:58:46,555 EPOCH 22: training on 2557278 raw words (2431478 effective words) took 1.5s, 1582583 effective words/s
2022-10-11 08:58:47,564 EPOCH 23 - PROGRESS: at 8.88% examples, 1731664 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:47,962 EPOCH 23: training on 2557278 raw words (2432189 effective words) took 1.4s, 1732001 effective words/s
2022-10-11 08:58:48,969 EPOCH 24 - PROGRESS: at 8.76% examples, 1701997 words/s, in_qsize 14, out_qsize 1
2022-10-11 08:58:49,383 EPOCH 24: training on 2557278 raw words (2431996 effective words) took 1.4s, 1713811 effective words/s
2022-10-11 08:58:50,395 EPOCH 25 - PROGRESS: at 8.26% examples, 1561688 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:50,999 EPOCH 25: training on 2557278 raw words (2432171 effective words) took 1.6s, 1508369 effective words/s
2022-10-11 08:58:52,009 EPOCH 26 - PROGRESS: at 8.47% examples, 1617313 words/s, in_qsize 12, out_qsize 1
2022-10-11 08:58:52,472 EPOCH 26: training on 2557278 raw words (2432022 effective words) took 1.5s, 1654116 effective words/s
2022-10-11 08:58:53,478 EPOCH 27 - PROGRESS: at 8.85% examples, 1730021 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:53,888 EPOCH 27: training on 2557278 raw words (2432424 effective words) took 1.4s, 1721251 effective words/s
2022-10-11 08:58:54,900 EPOCH 28 - PROGRESS: at 8.91% examples, 1738571 words/s, in_qsize 13, out_qsize 0
2022-10-11 08:58:55,321 EPOCH 28: training on 2557278 raw words (2432315 effective words) took 1.4s, 1701776 effective words/s
2022-10-11 08:58:56,324 EPOCH 29 - PROGRESS: at 8.36% examples, 1599613 words/s, in_qsize 12, out_qsize 1
2022-10-11 08:58:56,887 EPOCH 29: training on 2557278 raw words (2431927 effective words) took 1.6s, 1555284 effective words/s
2022-10-11 08:58:56,888 Word2Vec lifecycle event {'msg': 'training on 76718340 raw words (72954750 effective words) took 45.6s, 1599839 effective words/s', 'datetime': '2022-10-11T08:58:56.888198', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}
2022-10-11 08:58:56,896 destructive init_sims(replace=True) deprecated & no longer required for space-efficiency
2022-10-11 08:58:56,900 Word2Vec lifecycle event {'fname_or_handle': '../mimicdata/generated//disch_full.w2v', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-11T08:58:56.900191', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}
2022-10-11 08:58:56,900 not storing attribute cum_table
2022-10-11 08:58:56,939 saved ../mimicdata/generated//disch_full.w2v
2022-10-11 08:58:56,939 
**********************************************

2022-10-11 08:58:57,002 loading Word2Vec object from ../mimicdata/generated//disch_full.w2v
2022-10-11 08:58:57,035 loading wv recursively from ../mimicdata/generated//disch_full.w2v.wv.* with mmap=None
2022-10-11 08:58:57,035 setting ignored attribute cum_table to None
2022-10-11 08:58:57,505 Word2Vec lifecycle event {'fname': '../mimicdata/generated//disch_full.w2v', 'datetime': '2022-10-11T08:58:57.505818', 'gensim': '4.2.0', 'python': '3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}
2022-10-11 08:59:37,098 Size of training vocabulary (including PAD, UNK): 28283
