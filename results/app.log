2023-07-16 14:37:06,843 Namespace(log='INFO', random_seed=271, mode='train', data_setting='50', model='Transformer', num_epoch=[1, 100], learning_rate=[0.001], batch_size=128, max_len=200, embed_size=128, freeze_embed=True, label_attn_expansion=2, num_trans_layers=2, num_attn_heads=8, trans_forward_expansion=4, dropout_rate=0.1)

2023-07-16 14:37:08,113 In train set, average code counts per discharge summary: 1.0
2023-07-16 14:37:08,170 Final number of labels/codes: 48
2023-07-16 14:37:08,264 train set true item count: 31616


2023-07-16 14:37:08,947 In dev set, average code counts per discharge summary: 1.0
2023-07-16 14:37:08,988 Final number of labels/codes: 48
2023-07-16 14:37:09,051 dev set true item count: 10496


2023-07-16 14:37:09,272 In test set, average code counts per discharge summary: 1.0
2023-07-16 14:37:09,291 Final number of labels/codes: 48
2023-07-16 14:37:09,432 test set true item count: 10496


2023-07-16 14:37:09,729 Size of training vocabulary including PAD, UNK: 58350
2023-07-16 14:37:09,733 Building prefix dict from the default dictionary ...
2023-07-16 14:37:09,735 Loading model from cache C:\Users\acguc\AppData\Local\Temp\jieba.cache
2023-07-16 14:37:11,086 Loading model cost 1.353 seconds.
2023-07-16 14:37:11,087 Prefix dict has been built successfully.
2023-07-16 14:39:30,888 Taining labels are: ['A41.901', 'C11.900', 'C16.900', 'C18.900', 'C20.x00', 'C22.900', 'C34.90A', 'C50.900', 'D25.900', 'E11.401+', 'E11.900', 'H25.900', 'H81.901', 'I10.x05', 'I10.x0H', 'I24.901', 'I25.103', 'I61.900', 'I64.x00', 'J18.000', 'J18.900', 'J44.100', 'J98.414', 'K35.900', 'K40.901', 'K63.500', 'K65.000', 'K74.607', 'K85.900', 'K92.207', 'K92.208', 'K92.210', 'M06.900', 'N18.001', 'N63.x00', 'O34.201', 'O42.900', 'O47.100', 'O47.900', 'O60.200', 'P07.30A', 'R10.402', 'R50.900', 'R93.203', 'Z34.900', 'Z35.900', 'Z51.102', 'Z51.805']

2023-07-16 14:39:41,504 Total token count (including PAD, UNK) of full preprocessed discharge summaries: 58350
2023-07-16 14:39:42,785 Training with: HyperParams(learning_rate=0.001, num_epoch=1)
2023-07-16 14:39:42,786 Training Started...
2023-07-16 14:40:34,486 Training finished.

2023-07-16 14:41:29,094 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 14:41:29,098 target
2023-07-16 14:41:29,098 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 14:41:29,570 train Accuracy: 0.815441548582996
2023-07-16 14:41:33,932 train f1 score (micro): 0.815441548582996
2023-07-16 14:41:33,932 train f1 score (macro): 0.6314120101233862
2023-07-16 14:41:33,932 train auc score (micro): 0.9954555610398652
2023-07-16 14:41:33,932 train auc score (macro): 0.9907087696790956
2023-07-16 14:41:33,933 train precision at ks [1, 5, 8, 10, 15]: [0.815441548582996, 0.197564524291498, 0.12433182565789473, 0.09960146761133605, 0.06650008434547906]

2023-07-16 14:41:57,528 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 14:41:57,528 target
2023-07-16 14:41:57,529 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [1. 0. 0. ... 0. 0. 0.]]
2023-07-16 14:41:57,569 dev Accuracy: 0.7926829268292683
2023-07-16 14:41:58,694 dev f1 score (micro): 0.7926829268292683
2023-07-16 14:41:58,695 dev f1 score (macro): 0.6054607165442766
2023-07-16 14:41:58,695 dev auc score (micro): 0.9940503651885733
2023-07-16 14:41:58,695 dev auc score (macro): 0.9888820817989529
2023-07-16 14:41:58,695 dev precision at ks [1, 5, 8, 10, 15]: [0.7926829268292683, 0.19575076219512194, 0.12389243521341463, 0.09934260670731708, 0.06641260162601625]

2023-07-16 14:42:23,422 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 14:42:23,423 target
2023-07-16 14:42:23,423 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]]
2023-07-16 14:42:23,467 test Accuracy: 0.8024009146341463
2023-07-16 14:42:24,527 test f1 score (micro): 0.8024009146341463
2023-07-16 14:42:24,527 test f1 score (macro): 0.6214756638001354
2023-07-16 14:42:24,527 test auc score (micro): 0.9946741068903506
2023-07-16 14:42:24,527 test auc score (macro): 0.9895302769900889
2023-07-16 14:42:24,527 test precision at ks [1, 5, 8, 10, 15]: [0.8024009146341463, 0.19691310975609758, 0.12410680259146341, 0.09944740853658539, 0.06643165650406503]

2023-07-16 14:42:24,623 Training with: HyperParams(learning_rate=0.001, num_epoch=100)
2023-07-16 14:42:24,624 Training Started...
2023-07-16 15:39:18,158 Training finished.

2023-07-16 15:40:00,393 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:00,394 target
2023-07-16 15:40:00,394 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 1. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:00,514 train Accuracy: 0.9419281376518218
2023-07-16 15:40:03,479 train f1 score (micro): 0.9419281376518218
2023-07-16 15:40:03,480 train f1 score (macro): 0.9042245963009297
2023-07-16 15:40:03,480 train auc score (micro): 0.9997522244768606
2023-07-16 15:40:03,480 train auc score (macro): 0.9993860181480904
2023-07-16 15:40:03,480 train precision at ks [1, 5, 8, 10, 15]: [0.9419281376518218, 0.2, 0.125, 0.1, 0.06666666666666668]

2023-07-16 15:40:22,890 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:22,891 target
2023-07-16 15:40:22,891 [[0. 0. 0. ... 1. 0. 0.]
 [0. 0. 1. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 1. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:22,931 dev Accuracy: 0.7891577743902439
2023-07-16 15:40:24,476 dev f1 score (micro): 0.7891577743902439
2023-07-16 15:40:24,476 dev f1 score (macro): 0.6692374005688143
2023-07-16 15:40:24,476 dev auc score (micro): 0.9926567282839591
2023-07-16 15:40:24,476 dev auc score (macro): 0.9866235641772927
2023-07-16 15:40:24,476 dev precision at ks [1, 5, 8, 10, 15]: [0.7891577743902439, 0.19546493902439027, 0.12342797256097561, 0.09906631097560978, 0.06633003048780488]

2023-07-16 15:40:44,770 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:44,771 target
2023-07-16 15:40:44,771 [[0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 ...
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]
 [0. 0. 0. ... 0. 0. 0.]]
2023-07-16 15:40:44,808 test Accuracy: 0.7984946646341463
2023-07-16 15:40:45,749 test f1 score (micro): 0.7984946646341463
2023-07-16 15:40:45,749 test f1 score (macro): 0.6892397142931649
2023-07-16 15:40:45,749 test auc score (micro): 0.9949712023135793
2023-07-16 15:40:45,749 test auc score (macro): 0.9895721790508983
2023-07-16 15:40:45,749 test precision at ks [1, 5, 8, 10, 15]: [0.7984946646341463, 0.1972942073170732, 0.1241187118902439, 0.09949504573170734, 0.06647611788617887]

